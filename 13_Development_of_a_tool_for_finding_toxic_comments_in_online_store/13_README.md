# Разработка инструмента для поиска токсичных комментариев в интернет-магазине

Цель проекта: Ускорить модерацию комментариев в сообществе, автоматизировав оценку их токсичности: обучить модель классифицировать комментарии на позитивные и негативные.

Используемые библиотеки и инструменты: pandas, numpy, matplotlib, NLTK, sklearn, LightGBM.

Ход работы: 

1. Провести предобработку текста;
2. Выполнить токенизацию, то есть разбить на слова;
3. Лемматизация слов: приведение к начальной словарной форме;
4. Очистить текст от стоп-слов и ненужных символов;
5. Для корректной работы алгоритма добавить маркеры начала и конца предложения (они приравниваются к токенам).
6. На выходе у каждого исходного текста образуется свой список токенов.
7. Затем токены передать модели, которая переводит их в векторные представления. Для этого модель обращается к составленному заранее словарю токенов. На выходе для каждого текста образуются векторы заданной длины.
8. На финальном этапе передать модели признаки (векторы). И она спрогнозирует эмоциональную окраску текста — 0 («отрицательная») или 1 («положительная»).

Результат:
1. Проанализирован набор данных с разметкой о токсичности правок.
2. Выполнена очистка данных и разделение датасета на выборки.
3. Применен подход к векторизации текстов в датасете: TF-IDF.
4. Проведена лемматизация текста.
5. Протестированы разные модели классификации, подобраны гиперпараметры.
6. Выбрана лучшая модель, отвечающая заданному пороговому значению метрики F1.

Вывод: 
Из всех рассмотренных моделей искомой метрики смогла достигнуть только модель Linear Support Vector Classification. Логистическая регрессия, Случайный лес и LGBM-модель - их метрика была чуть ниже. Наиболее низкую метрику показало Дерево решений.


